{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1wkU-lbZmZzlMQjKaUCOtpd94is0y1abu","authorship_tag":"ABX9TyNBnlPu/axKDzrCyJbtQGkC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":24,"metadata":{"id":"uaQLffDjfIFD","executionInfo":{"status":"ok","timestamp":1731099571019,"user_tz":-60,"elapsed":297,"user":{"displayName":"Jochem","userId":"13741125791056547006"}}},"outputs":[],"source":["import numpy as np\n","import pickle\n","import pandas as pd\n","\n","from transformers import AutoTokenizer\n","from sentence_transformers import SentenceTransformer"]},{"cell_type":"markdown","source":["Source: https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb\n"],"metadata":{"id":"dVKdTv755GKT"}},{"cell_type":"markdown","source":["First, load the data set:"],"metadata":{"id":"QlQUGxBrgEft"}},{"cell_type":"code","source":["# load the data from the csv file\n","df = pd.read_csv(\"/content/drive/MyDrive/1Jupyter/SCRIPTIE/data.csv\")\n","\n","# load the mlb files back in, to get the classes and transform functions\n","with open(\"/content/drive/MyDrive/1Jupyter/SCRIPTIE/dom_mlb.pkl\", \"rb\") as f:\n","    dom_mlb = pickle.load(f)\n","\n","with open(\"/content/drive/MyDrive/1Jupyter/SCRIPTIE/sub_mlb.pkl\", \"rb\") as f:\n","    sub_mlb = pickle.load(f)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nw90JQmngKFm","executionInfo":{"status":"ok","timestamp":1731099571702,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jochem","userId":"13741125791056547006"}},"outputId":"3c8315f2-c99c-49b8-b5d1-ee457221d317"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.1.1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["Next, we want to tokenize all elements in X:"],"metadata":{"id":"baOvOQvyhwcE"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n","df[\"tokenized_text\"] = df[\"text\"].apply(lambda x: tokenizer(x, add_special_tokens=False))\n","print(type(df[\"tokenized_text\"][2]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9E0P9VAJf55_","executionInfo":{"status":"ok","timestamp":1731099574729,"user_tz":-60,"elapsed":1795,"user":{"displayName":"Jochem","userId":"13741125791056547006"}},"outputId":"91098589-15d6-4487-d8f4-ad6ddd523f60"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"]}]},{"cell_type":"markdown","source":["After tokenizing, we need to split the text up into chunks of 512, so the sentence bert model can generate its embeddings."],"metadata":{"id":"vAfovWCK-Z0v"}},{"cell_type":"code","source":["def chunk_text(tokens, chunk_size=512):\n","  if len(tokens[\"input_ids\"]) <= chunk_size:\n","    #print(tokens[\"input_ids\"], \"no chunk needed\")\n","    return [tokenizer.decode(tokens[\"input_ids\"])]\n","\n","  chunks = []\n","  for i in range(0, len(tokens[\"input_ids\"]), chunk_size):\n","      chunk = {k: t[i:i + chunk_size] for k, t in tokens.items()}\n","      chunks.append(tokenizer.decode(chunk[\"input_ids\"]))\n","\n","  return chunks"],"metadata":{"id":"MFrQteHmyC_Y","executionInfo":{"status":"ok","timestamp":1731099576406,"user_tz":-60,"elapsed":237,"user":{"displayName":"Jochem","userId":"13741125791056547006"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["chunked_text = df[\"tokenized_text\"].apply(lambda x: chunk_text(x, 512))\n","print(chunked_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnoZUXXX29Tb","executionInfo":{"status":"ok","timestamp":1731099581214,"user_tz":-60,"elapsed":3753,"user":{"displayName":"Jochem","userId":"13741125791056547006"}},"outputId":"36ab9def-6db5-4ed5-a353-2b05ad799212"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["0      [putin honours army unit blamed for bucha mass...\n","1      [europe putin thanks us journalist tucker carl...\n","2      [russia has a clear plan to resolve the confli...\n","3      [first war of tiktok era sees tragedy, humor a...\n","4      [ukraine's president zelenskyy to address mexi...\n","                             ...                        \n","621    [united kingdom : the country has been invaded...\n","622    [\" the fight against climate change is not on ...\n","623    [eu pulls out of hungarian foreign ministers'm...\n","624    [the new bonfires of the inquisition 1. the re...\n","625    [russia is giving up on kharkiv after â€˜ failur...\n","Name: tokenized_text, Length: 626, dtype: object\n"]}]},{"cell_type":"code","source":["bertmodel = SentenceTransformer(\"all-mpnet-base-v2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4NgJ8iQkLA4T","executionInfo":{"status":"ok","timestamp":1731099584073,"user_tz":-60,"elapsed":1118,"user":{"displayName":"Jochem","userId":"13741125791056547006"}},"outputId":"5facc7db-5aad-40ff-a8ae-98570a4d4bcb"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# maybe find a way to weigh the mean with the length of the text?\n","df[\"embeddings\"] = chunked_text.apply(lambda x: np.mean([bertmodel.encode(i) for i in x], axis = 0))"],"metadata":{"id":"_Q9YutKtU3TQ","executionInfo":{"status":"ok","timestamp":1731099608356,"user_tz":-60,"elapsed":22016,"user":{"displayName":"Jochem","userId":"13741125791056547006"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["print(df[\"embeddings\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15H69quSiD5H","executionInfo":{"status":"ok","timestamp":1731099608356,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jochem","userId":"13741125791056547006"}},"outputId":"c5a9d223-639c-4ae0-8c9d-18843b9c3b73"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["0      [0.05744616, 0.008171466, 0.039495505, -0.0038...\n","1      [-0.014265623, 0.07552964, 0.0051879473, 0.003...\n","2      [0.061988987, 0.007321683, 0.01204624, 0.01062...\n","3      [0.0643855, -0.030406523, -0.00027157273, -0.0...\n","4      [-0.012554288, 0.020935364, 0.0065615587, 0.02...\n","                             ...                        \n","621    [-0.01655262, -0.0051891557, -0.0009252665, -0...\n","622    [-0.005790931, 0.07960883, 0.0007383786, 0.038...\n","623    [0.023696497, -0.022049455, 0.0069245356, 0.00...\n","624    [0.008318179, 0.040885136, 0.016485114, 0.0215...\n","625    [0.039343122, 0.00335278, 0.018099703, 0.00574...\n","Name: embeddings, Length: 626, dtype: object\n"]}]},{"cell_type":"markdown","source":["Now that all of the texts are embedded, we want to predict something. So let's predict the dominant classes with a logistic regression classifier. The lr classifier is as follows:"],"metadata":{"id":"X0paMskPjPk3"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.multioutput import MultiOutputClassifier\n","\n","# when training on sub categories, some simply do not have enough data in the 600 point dataset... so for now only train it on the dominant categories\n","def logistic_regression_classifier(X_train, y_train, X_test):\n","    lr = MultiOutputClassifier(LogisticRegression(class_weight=\"balanced\", solver= \"liblinear\", max_iter=100))\n","    lr.fit(X_train, y_train)\n","\n","    y_pred = lr.predict(X_test)\n","    return y_pred\n"],"metadata":{"id":"Ybl0OVR7jgHs","executionInfo":{"status":"ok","timestamp":1731099608357,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jochem","userId":"13741125791056547006"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["Now, lets try to make some predictions using the bert embeddings:"],"metadata":{"id":"BCQqW7-0jqQd"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","X = np.vstack(df[\"embeddings\"].values)\n","y = df[dom_mlb.classes_].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n","\n","y_pred = logistic_regression_classifier(X_train=X_train,y_train=y_train,X_test=X_test)\n","\n","print(classification_report(y_true=y_test,y_pred=y_pred,target_names=dom_mlb.classes_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHxv3L4cjjuF","executionInfo":{"status":"ok","timestamp":1731100881279,"user_tz":-60,"elapsed":1427,"user":{"displayName":"Jochem","userId":"13741125791056547006"}},"outputId":"c038f7e3-624d-4b07-bcf9-0015799cf517"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                        precision    recall  f1-score   support\n","\n","                          CC: Amplifying Climate Fears       0.56      0.97      0.71        39\n","                      CC: Climate change is beneficial       0.00      0.00      0.00         2\n","              CC: Controversy about green technologies       0.29      0.50      0.36         8\n","                     CC: Criticism of climate movement       0.34      0.86      0.49        14\n","                     CC: Criticism of climate policies       0.24      1.00      0.38        17\n","         CC: Criticism of institutions and authorities       0.39      0.97      0.55        29\n","                        CC: Downplaying climate change       0.18      1.00      0.31         7\n","       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         1\n"," CC: Hidden plots by secret schemes of powerful groups       0.11      0.75      0.19         4\n","          CC: Questioning the measurements and science       0.21      1.00      0.34         5\n","                                                 Other       0.39      0.60      0.48        65\n","                     URW: Amplifying war-related fears       0.36      0.88      0.51        43\n","URW: Blaming the war on others rather than the invader       0.27      0.70      0.39        37\n","                             URW: Discrediting Ukraine       0.44      0.80      0.57        64\n","                 URW: Discrediting the West, Diplomacy       0.40      0.77      0.53        69\n","                           URW: Distrust towards Media       0.09      0.29      0.13         7\n","URW: Hidden plots by secret schemes of powerful groups       0.08      0.12      0.10         8\n","               URW: Negative Consequences for the West       0.17      0.58      0.27        19\n","                            URW: Overpraising the West       0.07      0.50      0.12         8\n","                                 URW: Praise of Russia       0.33      0.70      0.45        56\n","                             URW: Russia is the Victim       0.27      0.88      0.41        34\n","                         URW: Speculating war outcomes       0.17      0.65      0.27        17\n","\n","                                             micro avg       0.31      0.76      0.44       553\n","                                             macro avg       0.24      0.66      0.34       553\n","                                          weighted avg       0.34      0.76      0.46       553\n","                                           samples avg       0.34      0.75      0.42       553\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"markdown","source":["Let's see how well the model performs when utilizing LOOCV:"],"metadata":{"id":"o5hs_ZA9leVd"}},{"cell_type":"code","source":["from sklearn.model_selection import LeaveOneOut\n","from collections import Counter\n","\n","# function used by the majority classifier and the logistic regression with LOOCV to find the most commonly occuring label in a data set\n","def find_majority(y_train):\n","    y_tuples = [tuple(y) for y in y_train]\n","    max_y = Counter(y_tuples).most_common(1)\n","    max_y = np.array(max_y[0][0])\n","    return max_y\n","\n","# Does the logistic regression n times, if the data set is quite small\n","def logistic_regression_loocv(X, y, majority_ensemble = False, penalty =\"l2\", solver=\"liblinear\", max_iter = 100):\n","    # initialize the cross validation\n","    cv = LeaveOneOut()\n","    cv.get_n_splits(X)\n","\n","    # output arrays of the predicted label for that instance of y and the true label, so we can evaluate it later\n","    labels_pred = []\n","    labels_true = []\n","\n","    # Most common label = Other\n","    max_y = find_majority(y)\n","\n","    for i, (train_index, test_index) in enumerate(cv.split(X)):\n","        # Get the train and test instances for this fold\n","        X_train = X[train_index]\n","        y_train = y[train_index]\n","        X_test = X[test_index]\n","        y_test = y[test_index]\n","\n","        # LR doesn't work if one of the classes has no positive instances, skip if this happens\n","        valid_y = np.any(y_train != 0, axis=0)\n","        if not np.all(valid_y):\n","            print(f\"Skipped fold {i}, labels invalid\")\n","            continue\n","\n","        # If not invalid, train the classifier\n","        lr = MultiOutputClassifier(LogisticRegression(class_weight=\"balanced\", solver=solver, max_iter=max_iter, penalty=penalty))\n","        lr.fit(X_train,y_train)\n","\n","        # Make prediction for the test instance\n","        y_pred = lr.predict(X_test)\n","\n","        if(majority_ensemble):\n","            if np.all(y_pred == 0):\n","                y_pred = max_y\n","\n","        labels_pred.append(y_pred)\n","        labels_true.append(y_test)\n","\n","    # good format for classification report\n","    labels_pred = np.vstack(labels_pred)\n","    labels_true = np.vstack(labels_true)\n","    # print(\"Predicted Labels: \", labels_pred)\n","    # print(\"True Labels: \", labels_true)\n","\n","    return labels_pred, labels_true"],"metadata":{"id":"8IHz1wkIlKHg","executionInfo":{"status":"ok","timestamp":1731099726623,"user_tz":-60,"elapsed":256,"user":{"displayName":"Jochem","userId":"13741125791056547006"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["X = np.vstack(df[\"embeddings\"].values)\n","y = df[dom_mlb.classes_].values\n","\n","y_pred, y_true = logistic_regression_loocv(X,y,majority_ensemble=True)\n","print(classification_report(y_true = y_true, y_pred=y_pred, target_names=dom_mlb.classes_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6pVgyjUElknb","executionInfo":{"status":"ok","timestamp":1731100436851,"user_tz":-60,"elapsed":586646,"user":{"displayName":"Jochem","userId":"13741125791056547006"}},"outputId":"1004fb2b-53d0-463b-ec7f-212c41c75a3d"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                        precision    recall  f1-score   support\n","\n","                          CC: Amplifying Climate Fears       0.59      0.96      0.73        70\n","                      CC: Climate change is beneficial       0.08      0.67      0.14         3\n","              CC: Controversy about green technologies       0.20      0.80      0.31        10\n","                     CC: Criticism of climate movement       0.30      0.91      0.45        23\n","                     CC: Criticism of climate policies       0.31      0.89      0.46        38\n","         CC: Criticism of institutions and authorities       0.41      0.95      0.57        56\n","                        CC: Downplaying climate change       0.22      0.87      0.35        15\n","       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         2\n"," CC: Hidden plots by secret schemes of powerful groups       0.18      0.73      0.29        11\n","          CC: Questioning the measurements and science       0.12      0.88      0.22         8\n","                                                 Other       0.45      0.66      0.54       129\n","                     URW: Amplifying war-related fears       0.38      0.77      0.51        87\n","URW: Blaming the war on others rather than the invader       0.28      0.76      0.41        72\n","                             URW: Discrediting Ukraine       0.51      0.85      0.64       141\n","                 URW: Discrediting the West, Diplomacy       0.45      0.81      0.58       151\n","                           URW: Distrust towards Media       0.21      0.67      0.32        21\n","URW: Hidden plots by secret schemes of powerful groups       0.06      0.25      0.10        12\n","               URW: Negative Consequences for the West       0.20      0.68      0.31        40\n","                            URW: Overpraising the West       0.08      0.45      0.14        20\n","                                 URW: Praise of Russia       0.33      0.79      0.47       110\n","                             URW: Russia is the Victim       0.25      0.78      0.38        73\n","                         URW: Speculating war outcomes       0.20      0.76      0.32        37\n","\n","                                             micro avg       0.33      0.79      0.46      1129\n","                                             macro avg       0.26      0.72      0.37      1129\n","                                          weighted avg       0.37      0.79      0.50      1129\n","                                           samples avg       0.36      0.79      0.46      1129\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VTBNLxIzl3Rx"},"execution_count":null,"outputs":[]}]}